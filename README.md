# ğŸ“„ Semantic Research Paper Recommendation System

A **semantic research paper recommendation system** built using **Sentence-BERT embeddings**, **TF-IDF baselines**, and **Streamlit**.  
The system mimics search behavior by understanding the **semantic intent** behind user queries and retrieving research papers that are meaningfully relevant â€” not just keyword matched.

This project demonstrates **semantic search design**, **engineer-level model comparison**, and an interactive **UI for real-world usage**, inspired by production-grade retrieval systems.

---

## ğŸš€ Key Features

- ğŸ§  Uses **Sentence-BERT (SBERT)** to generate semantic embeddings of research abstracts  
- ğŸ” Computes **cosine similarity** between query and paper embeddings for ranking  
- ğŸ“Š Includes a **TF-IDF baseline** to show limitations of keyword-based retrieval  
- ğŸ“ˆ Manual relevance evaluation and explanation of similarity scores  
- ğŸ–¥ï¸ **Streamlit UI** for interactive paper recommendations  
- âš™ï¸ Offline embedding computation for fast inference  
- ğŸ“‚ Structured codebase with notebook prototyping and production code  

---

## ğŸ§  How It Works

The system processes research paper abstracts and converts them into dense vectors using a pre-trained SBERT model. During inference, a user enters a natural language query, which is also embedded. The system then ranks papers by cosine similarity between the query embedding and the precomputed paper embeddings.

To highlight the advantage of semantic representations, the system also implements a traditional **TF-IDF baseline**. While TF-IDF may produce higher raw cosine similarity due to keyword overlap, its results are often contextually irrelevant. In contrast, SBERT embeddings capture **meaning** and retrieve semantically aligned papers.

---

## ğŸ“‚ Project Structure

```
paper-recommendation-system/
â”‚
â”œâ”€â”€ app/
â”‚ â””â”€â”€ app.py # Streamlit UI application
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ processed_data.csv # Cleaned dataset for inference (ignored on GitHub)
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ embeddings.npy # Precomputed SBERT embeddings (ignored on GitHub)
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ Paper_Recommendation.ipynb # Notebook for EDA & comparison
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

```

> âš ï¸ Large files such as processed data and embeddings are excluded from version control via `.gitignore` to keep the repository lightweight.

---

## ğŸ§ª Dataset

- **Source:** arXiv research paper metadata  
- **Total papers:** ~1.7 million  
- **Subset used for experiments:** ~100,000  
- **Fields:** titles, abstracts, categories, metadata  

Due to memory and embedding computation constraints, a subset of approximately 100K papers was used. The design can be extended to the full dataset using scalable vector search techniques such as **FAISS**.

---

## ğŸ–¥ï¸ Streamlit Demo

The Streamlit UI allows users to:

- Enter a free-form research query  
- Select the number of papers to recommend  
- View recommended paper titles, categories, and similarity scores  
- Interactively explore semantic retrieval results  

### Run Locally

```
pip install -r requirements.txt
streamlit run app/app.py

```

The application launches in your browser at:

```

http://localhost:8501

```
---

## ğŸ“Š Evaluation Metrics

| Metric                         | Observation                                  |
|--------------------------------|----------------------------------------------|
| Semantic Relevance (SBERT)     | High quality, contextually relevant results |
| Lexical Matching (TF-IDF)      | Often retrieves irrelevant papers            |
| Similarity Score Comparison    | Not directly comparable across models        |
| Ranking Quality                | SBERT consistently performs better           |

Evaluation is performed through **qualitative inspection and manual relevance analysis** due to the absence of labeled relevance data.

---

## ğŸ§ª Notebook Usage

The Jupyter notebook is used for:

- Data preprocessing  
- Exploratory data analysis  
- Embedding generation  
- TF-IDF vs SBERT comparison  
- Result visualization  

> âš ï¸ Production logic is implemented only in `.py` files.  
> The notebook is strictly for experimentation and analysis.

---

## ğŸ’¡ Future Enhancements

- âš¡ Vector search using **FAISS** or other scalable indexes  
- ğŸ“¦ API deployment using **FastAPI** or similar frameworks  
- ğŸ” Advanced filtering by year, category, or author  
- ğŸŒ Hosted deployment (e.g., **Streamlit Cloud**)  
- ğŸ“ˆ Automated evaluation metrics with human feedback  

---

## ğŸ“Œ Why This Project Matters

This project demonstrates:

- Applied use of NLP and semantic search  
- Understanding of embedding spaces and similarity metrics  
- Proper baseline comparison and evaluation reasoning  
- Awareness of real-world constraints and practical deployment  
- Transition from a research notebook to a usable interactive application  

---

## ğŸ‘¤ Author

**Soumalya Sau**  
*M.Tech, IIT Kharagpur*  
**Interests:** Data Science, NLP, Semantic Search, GenAI, ML Systems
