{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmLgnAHhQg3b"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "JSON_PATH = \"/content/drive/MyDrive/arxiv/arxiv-metadata-oai-snapshot.json\""
      ],
      "metadata": {
        "id": "RXMQUYLEQ7BB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "6Q0ROqhVRCXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Stopwords loaded:\", len(stop_words))\n",
        "print(\"Lemmatizer ready:\", lemmatizer.lemmatize(\"running\"))"
      ],
      "metadata": {
        "id": "z1WMw4InRIbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop_words]\n",
        "    return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "wdZCvJ_sTQDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_PAPERS = 100000   # adjust based on RAM (50kâ€“200k safe)\n",
        "\n",
        "data = []\n",
        "with open(JSON_PATH, \"r\") as f:\n",
        "    for i, line in enumerate(f):\n",
        "        if i >= MAX_PAPERS:\n",
        "            break\n",
        "        paper = json.loads(line)\n",
        "        data.append({\n",
        "            \"title\": paper.get(\"title\", \"\"),\n",
        "            \"abstract\": paper.get(\"abstract\", \"\"),\n",
        "            \"categories\": paper.get(\"categories\", \"\")\n",
        "        })\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df[\"text\"] = (df[\"title\"] + \" \" + df[\"abstract\"]).apply(clean_text)\n",
        "\n",
        "print(\"Total papers loaded:\", len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "upNM_txWUjoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "zaWxuwUSVNiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# Exploratory Data Analysis\n",
        "# =========================\n",
        "\n",
        "print(f\"Total papers used for experiments: {len(df)}\")\n",
        "\n",
        "# Text length statistics\n",
        "df[\"text_length\"] = df[\"text\"].apply(lambda x: len(x.split()))\n",
        "print(\"\\nText Length Statistics:\")\n",
        "print(df[\"text_length\"].describe())\n",
        "\n",
        "# Category distribution\n",
        "print(\"\\nTop 10 Categories:\")\n",
        "print(df[\"categories\"].value_counts().head(10))"
      ],
      "metadata": {
        "id": "O0M9IC64Z0CO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis Insights\n",
        "\n",
        "- The experiment uses 100,000 research papers sampled from the full arXiv corpus (~1.7M papers).\n",
        "- The average abstract length is ~82 words, with some abstracts exceeding 300 words.\n",
        "- The dataset spans multiple scientific domains, with a higher concentration in physics-related categories such as astro-ph, hep-ph, and quant-ph.\n",
        "- Due to the length and technical nature of abstracts, semantic embedding models are more suitable than keyword-based methods."
      ],
      "metadata": {
        "id": "Vw94lukGbPcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers"
      ],
      "metadata": {
        "id": "lfHXkQ0grKE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "wR7usepXrLjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_embeddings = embedder.encode(\n",
        "    df[\"text\"].tolist(),\n",
        "    batch_size=32,\n",
        "    show_progress_bar=True\n",
        ")"
      ],
      "metadata": {
        "id": "UUs4u5mEW9Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"/content/drive/MyDrive/arxiv/document_embeddings.npy\", document_embeddings)"
      ],
      "metadata": {
        "id": "hKei-jK3XAkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_papers(query, top_k=5):\n",
        "    query_clean = clean_text(query)\n",
        "    query_embedding = embedder.encode([query_clean])\n",
        "\n",
        "    scores = cosine_similarity(query_embedding, document_embeddings)[0]\n",
        "    top_idx = np.argsort(scores)[-top_k:][::-1]\n",
        "\n",
        "    results = df.iloc[top_idx][[\"title\", \"categories\"]].copy()\n",
        "    results[\"similarity_score\"] = scores[top_idx]\n",
        "\n",
        "    return results.reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "CxxHuu7cvTQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"transformer models for language understanding\"\n",
        "recommend_papers(query, top_k=5)"
      ],
      "metadata": {
        "id": "jG8Gzzb7vndd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# TF-IDF Baseline Model\n",
        "# =========================\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=30000,   # memory-safe for 100k docs\n",
        "    stop_words=\"english\"\n",
        ")\n",
        "\n",
        "tfidf_matrix = tfidf.fit_transform(df[\"text\"])\n",
        "\n",
        "print(\"TF-IDF matrix shape:\", tfidf_matrix.shape)"
      ],
      "metadata": {
        "id": "x25gIPYevrjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tfidf_recommend(query, top_k=5):\n",
        "    query_clean = clean_text(query)\n",
        "    q_vec = tfidf.transform([query_clean])\n",
        "\n",
        "    scores = cosine_similarity(q_vec, tfidf_matrix)[0]\n",
        "    top_idx = np.argsort(scores)[-top_k:][::-1]\n",
        "\n",
        "    results = df.iloc[top_idx][[\"title\", \"categories\"]].copy()\n",
        "    results[\"similarity_score\"] = scores[top_idx]\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "p55mHoHMdA5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"transformer models for language understanding\"\n",
        "\n",
        "print(\"ðŸ”¹ SBERT Results:\")\n",
        "print(recommend_papers(query, top_k=5))\n",
        "\n",
        "print(\"\\nðŸ”¹ TF-IDF Results:\")\n",
        "print(tfidf_recommend(query, top_k=5))"
      ],
      "metadata": {
        "id": "4xUY28CTdIVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results and Discussion\n",
        "\n",
        "This project compares a keyword-based retrieval method (TF-IDF) with a semantic embedding-based method (Sentence-BERT) for research paper recommendation.\n",
        "\n",
        "TF-IDF represents documents as sparse vectors based on word frequencies and computes similarity using cosine similarity. It relies on exact word overlap and does not capture semantic meaning. As a result, documents with common keywords may receive high similarity scores even if they are contextually irrelevant.\n",
        "\n",
        "Sentence-BERT (SBERT) generates dense semantic embeddings that capture the contextual meaning of text. Cosine similarity in this embedding space reflects semantic closeness rather than lexical overlap, making SBERT more suitable for long and technical abstracts.\n",
        "\n",
        "In the observed results, SBERT retrieves papers that are semantically aligned with the query, while TF-IDF often retrieves keyword-matched but irrelevant documents. Although TF-IDF produces higher cosine similarity values, these scores are not directly comparable to SBERT scores because they are computed in fundamentally different vector spaces.\n",
        "\n",
        "Overall, SBERT provides more accurate and meaningful recommendations by capturing semantic relationships, whereas TF-IDF is limited to surface-level keyword matching."
      ],
      "metadata": {
        "id": "vD3zNtxff2Op"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_PATH = \"/content/drive/MyDrive/arxiv\"\n",
        "# Create a processed data folder if it doesn't exist\n",
        "processed_dir = os.path.join(BASE_PATH, \"processed\")\n",
        "\n",
        "os.makedirs(processed_dir, exist_ok=True)\n",
        "\n",
        "# Save processed dataframe\n",
        "processed_file_path = os.path.join(processed_dir, \"processed_data.csv\")\n",
        "df.to_csv(processed_file_path, index=False)\n",
        "\n",
        "print(\"âœ… Processed data saved successfully at:\")\n",
        "print(processed_file_path)"
      ],
      "metadata": {
        "id": "4qNhpiSRlckd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ye-NEIChpWRK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}